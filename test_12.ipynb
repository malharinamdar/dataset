{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMyTV28WOW-u"
   },
   "source": [
    "Testing 100k Hindi dataset\n",
    "Load the CSV file into the folder where the notebook is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xi1u6rrDOW-y",
    "outputId": "7f499c25-91c2-4354-c08f-c81a63b426c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nanoGPT' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Clone the NanoGPT\n",
    "!git clone https://github.com/karpathy/nanoGPT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXrxkIFmOW-1",
    "outputId": "6f3c98e4-3785-49c1-f7b9-982a1ec5094c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.18.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.17.0)\n",
      "Requirement already satisfied: setproctitle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-8X6jdabOW-2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import nanoGPT.model as GPT\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DV7k7sVQOW-2"
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# # Load API keys https://www.kaggle.com/discussions/product-feedback/114053\n",
    "# secret_label = \"WANDB_API_KEY\"\n",
    "my_secret = \"c2e3619f245387906ce0bd58733dc79534a116bc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hSzqFTpuOW-3"
   },
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    block_size: int = 256\n",
    "    vocab_size: int = 65400  # Increased to handle the full token range (65398 + some padding)\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 192\n",
    "    dropout: float = 0.2\n",
    "    bias: bool = True\n",
    "\n",
    "config = GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNR6eoiyOW-4",
    "outputId": "df386a24-c408-4f4a-d0db-92802d93ea80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block_size': 256,\n",
       " 'vocab_size': 65400,\n",
       " 'n_layer': 12,\n",
       " 'n_head': 8,\n",
       " 'n_embd': 192,\n",
       " 'dropout': 0.2,\n",
       " 'bias': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_config = {k:v for k,v in vars(config).items() if not callable(getattr(config, k)) and not k.startswith(\"__\")} # Creating Wandb hyperparameters config for tracking experiements\n",
    "wandb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EwY_PqyOW-4",
    "outputId": "abbbbc18-a98d-42b0-9567-e5517554f4a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnisargbhavsar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/malhar.inamdar/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1do-5vNOW-5"
   },
   "source": [
    "                                        Read the Hindi CSV file , create train & validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcGM7jqYOW-5",
    "outputId": "b6a7ccea-0735-46a0-f8af-797a0822be80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset processed from: /Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000.csv\n",
      "Total texts: 99984\n",
      "Training texts: 79987\n",
      "Validation texts: 19997\n",
      "Training texts saved to: /Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000_train.csv\n",
      "Validation texts saved to: /Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000_val.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_script_directory():\n",
    "    \"\"\"\n",
    "    Get the directory of the current script, working across different environments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str: Directory path of the current script or current working directory\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        return os.getcwd()\n",
    "\n",
    "def prepare_hindi_text_dataset(\n",
    "    filename,\n",
    "    text_column_index=0,  # Default to first column\n",
    "    train_size=0.8,\n",
    "    random_state=42,\n",
    "    search_paths=None,\n",
    "    encoding='utf-8'\n",
    "):\n",
    "    \"\"\"\n",
    "    Read a CSV file without headers and create train/validation splits.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filename : str\n",
    "        Name of the CSV file\n",
    "    text_column_index : int, optional (default=0)\n",
    "        Index of the column containing text data\n",
    "    train_size : float, optional (default=0.8)\n",
    "        Proportion of data to use for training (remaining for validation)\n",
    "    random_state : int, optional (default=42)\n",
    "        Seed for random split reproducibility\n",
    "    search_paths : list, optional\n",
    "        Additional paths to search for the file\n",
    "    encoding : str, optional (default='utf-8')\n",
    "        Encoding of the CSV file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (train_texts, val_texts)\n",
    "        Lists of training and validation texts\n",
    "    \"\"\"\n",
    "    # Add default search paths\n",
    "    if search_paths is None:\n",
    "        search_paths = [\n",
    "            get_script_directory(),\n",
    "            os.getcwd(),\n",
    "            os.path.expanduser('~')\n",
    "        ]\n",
    "\n",
    "    # Try to find the file in the search paths\n",
    "    csv_path = None\n",
    "    for path in search_paths:\n",
    "        potential_path = os.path.join(path, filename)\n",
    "        if os.path.exists(potential_path):\n",
    "            csv_path = potential_path\n",
    "            break\n",
    "\n",
    "    # Raise error if file not found\n",
    "    if csv_path is None:\n",
    "        raise FileNotFoundError(f\"Could not find {filename} in the specified search paths.\")\n",
    "\n",
    "    try:\n",
    "        # Read CSV file without headers\n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            encoding=encoding,\n",
    "            header=None  # No header row\n",
    "        )\n",
    "\n",
    "        # Validate text column index\n",
    "        if text_column_index >= len(df.columns):\n",
    "            raise ValueError(f\"Column index {text_column_index} is out of range.\")\n",
    "\n",
    "        # Select the specified column\n",
    "        texts = df[text_column_index].tolist()\n",
    "\n",
    "        # Remove any rows with NaN or empty values\n",
    "        texts = [str(text).strip() for text in texts if pd.notna(text) and str(text).strip()]\n",
    "\n",
    "        # Split into train and validation sets\n",
    "        train_texts, val_texts = train_test_split(\n",
    "            texts,\n",
    "            train_size=train_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        print(f\"Dataset processed from: {csv_path}\")\n",
    "        print(f\"Total texts: {len(texts)}\")\n",
    "        print(f\"Training texts: {len(train_texts)}\")\n",
    "        print(f\"Validation texts: {len(val_texts)}\")\n",
    "\n",
    "        return train_texts, val_texts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocessing function for Hindi text.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text to preprocess\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # Comprehensive text preprocessing for Hindi\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove leading/trailing whitespaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Optional: Add more preprocessing steps for Hindi text\n",
    "    # - Convert to lowercase\n",
    "    # - Remove extra whitespaces\n",
    "    # - Remove special characters if needed\n",
    "\n",
    "    return text\n",
    "\n",
    "def save_processed_datasets(train_texts, val_texts, original_filename):\n",
    "    \"\"\"\n",
    "    Save processed train and validation texts to CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_texts : list\n",
    "        List of training texts\n",
    "    val_texts : list\n",
    "        List of validation texts\n",
    "    original_filename : str\n",
    "        Original filename to base output filenames on\n",
    "    \"\"\"\n",
    "    # Get the directory to save files\n",
    "    save_dir = get_script_directory()\n",
    "\n",
    "    # Create output filenames based on original filename\n",
    "    base_name = os.path.splitext(original_filename)[0]\n",
    "    train_output = os.path.join(save_dir, f\"{base_name}_train.csv\")\n",
    "    val_output = os.path.join(save_dir, f\"{base_name}_val.csv\")\n",
    "\n",
    "    # Save train texts\n",
    "    pd.DataFrame(train_texts, columns=['text']).to_csv(train_output, index=False, encoding='utf-8')\n",
    "    print(f\"Training texts saved to: {train_output}\")\n",
    "\n",
    "    # Save validation texts\n",
    "    pd.DataFrame(val_texts, columns=['text']).to_csv(val_output, index=False, encoding='utf-8')\n",
    "    print(f\"Validation texts saved to: {val_output}\")\n",
    "\n",
    "def main():\n",
    "    # Specify filename\n",
    "    filename = '/Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000.csv'  # Replace with your actual filename\n",
    "\n",
    "    # You can optionally specify additional search paths\n",
    "    search_paths = [\n",
    "        os.getcwd(),  # Current working directory\n",
    "        os.path.expanduser('~/Documents'),  # Example additional path\n",
    "    ]\n",
    "\n",
    "    # Prepare dataset\n",
    "    train_texts, val_texts = prepare_hindi_text_dataset(\n",
    "        filename,\n",
    "        text_column_index=0,  # Use first column, adjust if needed\n",
    "        train_size=0.8,  # 80% train, 20% validation\n",
    "        search_paths=search_paths,  # Optional: additional search paths\n",
    "        encoding='utf-8'  # Specify encoding for Hindi text\n",
    "    )\n",
    "\n",
    "    # Optional: Apply preprocessing\n",
    "    if train_texts:\n",
    "        train_texts = [preprocess_text(text) for text in train_texts]\n",
    "        val_texts = [preprocess_text(text) for text in val_texts]\n",
    "\n",
    "        # Optional: Save processed datasets\n",
    "        save_processed_datasets(train_texts, val_texts, filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2R1akCtOW-7"
   },
   "source": [
    "                                                      Toeknize the dataset, Create the binary files for model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309,
     "referenced_widgets": [
      "e331ffd1870f4cd783c550121d2fd8f4",
      "00c4c17b9c2a44aba123fbc1990dbdf6",
      "e1cb9fd654b24af39efb5ca966cc899d",
      "2e576622c15843b681d0b2ece9e59df8",
      "aed6aa1b5b2b4d8b8bb044f247b5c2b4",
      "a0482b60ad9c489b9669d77a22619106",
      "988e434de15e4a9dbfc84e098db9b6fd",
      "95bd9b75164347f286c0a0fcb46e2338",
      "6d1b2d51747a49ef8418aeead2870a49",
      "1608adce0c5a46c4b79792468e3f752e",
      "c96852b060544250b5f981745e16a8ed",
      "a86180aae66840eab98803c8d700ae0e",
      "beb4e69e8efb42f096c64af772a89d33",
      "a6676f1c07304d8699631a5f9312a736",
      "73a244947f364462ba648439dd20d62d",
      "7bf4e9376c914f9cb525901ca61ff1a6",
      "39732ae7fbb64ada9c507617cc7e2ae8",
      "da8e8b8bfc894b98b11133aaea98cc71",
      "3685092aa2c04c7887f9c4be409f38f6",
      "e9dbbb22cb8d4ed99cc3825b4a47fe94",
      "19f45cdd0e0c4137a0449fe1e990fa69",
      "aaf94ea3be8a4773bbd0e302f14c0879"
     ]
    },
    "id": "qOJdFIzDOW-7",
    "outputId": "cb7cdb06-6507-47fa-d6d2-48dd1961555f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- tokenization_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Writing train.bin: 100%|██████████| 1024/1024 [00:01<00:00, 863.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset saved to: train.bin\n",
      "Total tokens: 20475851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing val.bin: 100%|██████████| 1024/1024 [00:00<00:00, 3505.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset saved to: val.bin\n",
      "Total tokens: 5119129\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def tokenize_dataset(\n",
    "    csv_file_path,\n",
    "    tokenizer_model=\"ai4bharat/indictrans2-en-indic-dist-200M\",\n",
    "    output_bin_file=None,\n",
    "    num_proc=8\n",
    "):\n",
    "    \"\"\"\n",
    "    Tokenize a CSV dataset using IndicTrans Toolkit and create a binary file for training.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_file_path : str\n",
    "        Path to the CSV file containing texts\n",
    "    tokenizer_model : str, optional\n",
    "        Hugging Face tokenizer model to use (default: IndicTrans model)\n",
    "    output_bin_file : str, optional\n",
    "        Output binary filename (defaults to CSV filename with .bin extension)\n",
    "    num_proc : int, optional\n",
    "        Number of processors to use for tokenization\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.memmap: Tokenized dataset as a memory-mapped array\n",
    "    \"\"\"\n",
    "    # Validate file exists\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_file_path}\")\n",
    "\n",
    "    # Initialize IndicTrans components\n",
    "    ip = IndicProcessor(inference=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_model, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(tokenizer_model, trust_remote_code=True)\n",
    "\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Ensure 'text' column exists\n",
    "    if 'text' not in df.columns:\n",
    "        # If no column name, assume first column is text\n",
    "        df.columns = ['text']\n",
    "\n",
    "    # Tokenization function\n",
    "    def process_text(text):\n",
    "        try:\n",
    "            # Preprocess text for IndicTrans\n",
    "            batch = ip.preprocess_batch([str(text)], src_lang=\"hin_Deva\", tgt_lang=\"hin_Deva\")\n",
    "            encoded = tokenizer(batch, padding=\"longest\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "            return {\n",
    "                'ids': encoded[\"input_ids\"].squeeze().tolist(),\n",
    "                'len': len(encoded[\"input_ids\"].squeeze())\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Tokenization error for text: {text}, Error: {e}\")\n",
    "            return {'ids': [], 'len': 0}\n",
    "\n",
    "    # Tokenize all texts\n",
    "    tokenized_texts = [process_text(text) for text in df['text']]\n",
    "\n",
    "    # Calculate total length and prepare output file\n",
    "    arr_len = np.sum([item['len'] for item in tokenized_texts], dtype=np.uint64)\n",
    "\n",
    "    # Determine appropriate dtype based on tokenizer vocab size\n",
    "    max_token_value = tokenizer.vocab_size\n",
    "    if max_token_value < 2**16:\n",
    "        dtype = np.uint16\n",
    "    elif max_token_value < 2**32:\n",
    "        dtype = np.uint32\n",
    "    else:\n",
    "        dtype = np.uint64\n",
    "\n",
    "    # Generate output filename if not provided\n",
    "    if output_bin_file is None:\n",
    "        output_bin_file = os.path.splitext(csv_file_path)[0] + '.bin'\n",
    "\n",
    "    # Create memory-mapped array\n",
    "    arr = np.memmap(output_bin_file, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "\n",
    "    # Write tokenized data\n",
    "    idx = 0\n",
    "    total_batches = 1024\n",
    "    for batch_idx in tqdm(range(total_batches), desc=f'Writing {output_bin_file}'):\n",
    "        # Simulate batching\n",
    "        start = (batch_idx * len(tokenized_texts)) // total_batches\n",
    "        end = ((batch_idx + 1) * len(tokenized_texts)) // total_batches\n",
    "\n",
    "        batch = tokenized_texts[start:end]\n",
    "        arr_batch = np.concatenate([item['ids'] for item in batch])\n",
    "\n",
    "        # Write into mmap\n",
    "        arr[idx: idx + len(arr_batch)] = arr_batch\n",
    "        idx += len(arr_batch)\n",
    "\n",
    "    arr.flush()\n",
    "\n",
    "    print(f\"Tokenized dataset saved to: {output_bin_file}\")\n",
    "    print(f\"Total tokens: {arr_len}\")\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths to train and validation CSV files\n",
    "    train_csv = '/Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000_train.csv'\n",
    "    val_csv = '/Users/malhar.inamdar/Desktop/task/tinystories_hindi_first_100000_val.csv'\n",
    "\n",
    "    # Tokenize train dataset\n",
    "    train_tokens = tokenize_dataset(\n",
    "        train_csv,\n",
    "        tokenizer_model=\"ai4bharat/indictrans2-en-indic-dist-200M\",\n",
    "        output_bin_file='train.bin'\n",
    "    )\n",
    "\n",
    "    # Tokenize validation dataset\n",
    "    val_tokens = tokenize_dataset(\n",
    "        val_csv,\n",
    "        tokenizer_model=\"ai4bharat/indictrans2-en-indic-dist-200M\",\n",
    "        output_bin_file='val.bin'\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvkP7tQ1OW-9"
   },
   "source": [
    "                                                                    Check the tokenizer, bin files - Troubleshooting part of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0PHK3GoOW-9",
    "outputId": "4978e9d6-79b3-4804-8601-e3258af18f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Binary File Analysis: train.bin\n",
      "--------------------------------------------------\n",
      "Detected Data Type: <class 'numpy.uint16'>\n",
      "Total Number of Tokens: 20475851\n",
      "Vocabulary Size: 32322\n",
      "Token Range: 2 - 30659\n",
      "\n",
      "Token Samples:\n",
      "Raw Token IDs: [16070  6764 14695 18656 26047     7   103 13133 16070 25485]\n",
      "\n",
      "Detokenized Sample:   ंायोथ, -तंध\n",
      "\n",
      "Memory Usage: 39.05 MB\n",
      "\n",
      "============================================================\n",
      "Binary File Analysis: val.bin\n",
      "--------------------------------------------------\n",
      "Detected Data Type: <class 'numpy.uint16'>\n",
      "Total Number of Tokens: 5119129\n",
      "Vocabulary Size: 32322\n",
      "Token Range: 2 - 30659\n",
      "\n",
      "Token Samples:\n",
      "Raw Token IDs: [  277   277 10017   277   277 14376   277   277 26474 26308]\n",
      "\n",
      "Detokenized Sample:   क  ी  ।ख\n",
      "\n",
      "Memory Usage: 9.76 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def inspect_bin_file(\n",
    "    bin_file_path,\n",
    "    tokenizer_model=\"ai4bharat/indictrans2-en-indic-dist-200M\",\n",
    "    num_samples=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Inspect a binary file created from tokenization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bin_file_path : str\n",
    "        Path to the .bin file\n",
    "    tokenizer_model : str, optional\n",
    "        Tokenizer model used for original tokenization\n",
    "    num_samples : int, optional\n",
    "        Number of token samples to display\n",
    "    \"\"\"\n",
    "    # Validate file exists\n",
    "    if not os.path.exists(bin_file_path):\n",
    "        raise FileNotFoundError(f\"Binary file not found: {bin_file_path}\")\n",
    "\n",
    "    # Initialize tokenizer for potential detokenization\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_model, trust_remote_code=True)\n",
    "\n",
    "    # Detect appropriate dtype based on file size and content\n",
    "    def detect_dtype(file_path):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "\n",
    "        # Try different dtypes\n",
    "        dtype_options = [\n",
    "            (np.uint16, 2),\n",
    "            (np.uint32, 4),\n",
    "            (np.uint64, 8)\n",
    "        ]\n",
    "\n",
    "        for dtype, bytes_per_element in dtype_options:\n",
    "            # Check if file size is divisible by dtype size\n",
    "            if file_size % bytes_per_element == 0:\n",
    "                # Load a small sample to check\n",
    "                try:\n",
    "                    sample = np.memmap(file_path, dtype=dtype, mode='r', shape=(10,))\n",
    "                    # Check if sample values are within reasonable token range\n",
    "                    if sample.max() < tokenizer.vocab_size:\n",
    "                        return dtype\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        # Fallback\n",
    "        return np.uint32\n",
    "\n",
    "    # Detect dtype\n",
    "    detected_dtype = detect_dtype(bin_file_path)\n",
    "\n",
    "    # Load the entire file\n",
    "    tokens = np.memmap(bin_file_path, dtype=detected_dtype, mode='r')\n",
    "\n",
    "    # Print file information\n",
    "    print(f\"Binary File Analysis: {bin_file_path}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Detected Data Type: {detected_dtype}\")\n",
    "    print(f\"Total Number of Tokens: {len(tokens)}\")\n",
    "    print(f\"Vocabulary Size: {tokenizer.vocab_size}\")\n",
    "\n",
    "    # Validate token range\n",
    "    max_token = tokens.max()\n",
    "    min_token = tokens.min()\n",
    "    print(f\"Token Range: {min_token} - {max_token}\")\n",
    "\n",
    "    # Sample tokens\n",
    "    print(\"\\nToken Samples:\")\n",
    "    sample_indices = np.random.choice(len(tokens), min(num_samples, len(tokens)), replace=False)\n",
    "    sample_tokens = tokens[sample_indices]\n",
    "\n",
    "    print(\"Raw Token IDs:\", sample_tokens)\n",
    "\n",
    "    # Optional: Detokenize sample tokens\n",
    "    try:\n",
    "        detokenized_samples = tokenizer.decode(sample_tokens.tolist())\n",
    "        print(\"\\nDetokenized Sample:\", detokenized_samples)\n",
    "    except Exception as e:\n",
    "        print(\"Could not detokenize samples:\", str(e))\n",
    "\n",
    "    # Memory usage\n",
    "    memory_usage = tokens.nbytes / (1024 * 1024)  # Convert to MB\n",
    "    print(f\"\\nMemory Usage: {memory_usage:.2f} MB\")\n",
    "\n",
    "def main():\n",
    "    # List of bin files to inspect\n",
    "    bin_files = ['train.bin', 'val.bin']\n",
    "\n",
    "    for bin_file in bin_files:\n",
    "        if os.path.exists(bin_file):\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            inspect_bin_file(bin_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMoAKXT1OW--"
   },
   "source": [
    "                                                                                                       File Processing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oB48zRC0OW--"
   },
   "outputs": [],
   "source": [
    "def process_data_files():\n",
    "    # Read and process training data\n",
    "    train_data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    val_data = np.memmap('val.bin', dtype=np.uint16, mode='r')\n",
    "\n",
    "    # Verify token ranges\n",
    "    max_token = max(train_data.max(), val_data.max())\n",
    "    min_token = min(train_data.min(), val_data.min())\n",
    "\n",
    "    print(f\"Token range in data: {min_token} - {max_token}\")\n",
    "    print(f\"Total tokens in training: {len(train_data)}\")\n",
    "    print(f\"Total tokens in validation: {len(val_data)}\")\n",
    "\n",
    "    return max_token + 1  # +1 because token indices are 0-based\n",
    "\n",
    "def get_batch(split, block_size, batch_size, device):\n",
    "    # Load appropriate data file\n",
    "    data = np.memmap(f\"{split}.bin\", dtype=np.uint16, mode='r')\n",
    "\n",
    "    # Generate random starting indices\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "\n",
    "    # Extract sequences\n",
    "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
    "\n",
    "    # Move to device\n",
    "    if device == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Function to verify configuration\n",
    "def verify_config(config, actual_vocab_size):\n",
    "    if config.vocab_size < actual_vocab_size:\n",
    "        raise ValueError(f\"Config vocab_size ({config.vocab_size}) is smaller than actual vocab size ({actual_vocab_size})\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "doPr0kPvOW-_",
    "outputId": "990d7911-f0e8-48ef-f38e-f16670a42c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token range in data: 2 - 30659\n",
      "Total tokens in training: 20475851\n",
      "Total tokens in validation: 5119129\n",
      "number of parameters: 17.90M\n"
     ]
    }
   ],
   "source": [
    "# Verify data and configuration\n",
    "actual_vocab_size = process_data_files()\n",
    "config = GPTConfig()\n",
    "verify_config(config, actual_vocab_size)\n",
    "\n",
    "# Initialize model with new config\n",
    "nanoGPT = GPT.GPT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwtq4ss7OW-_"
   },
   "source": [
    "                                                        Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QUgujgRCOW_A"
   },
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    \"\"\"Get a batch of data for training or validation.\"\"\"\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap('val.bin', dtype=np.uint16, mode='r')\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9qBKR8nOW_A"
   },
   "source": [
    "                                                         Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fppiSBEjOW_A",
    "outputId": "903ce2aa-6dca-41b6-fe84-80cb0c9191eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1665c3810>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 5e-5  # Slower learning rate for stability with large models\n",
    "max_iters = 80000  # Increase iterations for sufficient training\n",
    "warmup_steps = 2000  # More gradual warmup\n",
    "min_lr = 1e-5  # Lower minimum learning rate for fine-tuning\n",
    "eval_iters = 1000  # Evaluate less frequently to save compute\n",
    "\n",
    "batch_size = 8  # Smaller batch size due to model size and memory constraints\n",
    "block_size = 256  # Increased for capturing longer contexts\n",
    "gradient_accumulation_steps = 64  # Compensate for reduced batch size\n",
    "\n",
    "\n",
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "\n",
    "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxNqarUvOW_B",
    "outputId": "265feb9a-a83c-4938-da24-3206cdd8b29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 17.90M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
    "\n",
    "nanoGPT = GPT.GPT(config)\n",
    "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
    "optimizer =  torch.optim.AdamW(nanoGPT.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
    "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
    "\n",
    "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOX_dQssOW_B"
   },
   "source": [
    "                                                   RUN THE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "dGefNxUxOW_C",
    "outputId": "89b87374-cd3c-4b99-e1e8-18f813000ffc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/malhar.inamdar/Downloads/wandb/run-20241125_014442-z09dzuyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nisargbhavsar/nanogpt-tinystories/runs/z09dzuyl' target=\"_blank\">nanoGPT-sml-longer</a></strong> to <a href='https://wandb.ai/nisargbhavsar/nanogpt-tinystories' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nisargbhavsar/nanogpt-tinystories' target=\"_blank\">https://wandb.ai/nisargbhavsar/nanogpt-tinystories</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nisargbhavsar/nanogpt-tinystories/runs/z09dzuyl' target=\"_blank\">https://wandb.ai/nisargbhavsar/nanogpt-tinystories/runs/z09dzuyl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80000 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  0%|          | 90/80000 [04:52<72:13:51,  3.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m nanoGPT(X, y)\n\u001b[1;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m gradient_accumulation_steps \u001b[38;5;66;03m# scale the loss to account for gradient accumulation\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m gradient_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m max_iters):\n\u001b[1;32m     34\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(nanoGPT\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:516\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"nanogpt-tinystories\", name=\"nanoGPT-sml-longer\", config=wandb_config)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "for epoch in tqdm(range(max_iters)):\n",
    "    if epoch%eval_iters == 0 and epoch != 0:\n",
    "        losses = estimate_loss(nanoGPT)\n",
    "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "        train_loss_list += [losses['train']]\n",
    "        validation_loss_list += [losses['val']]\n",
    "\n",
    "        wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train/loss\": losses['train'],\n",
    "                \"val/loss\": losses['val'],\n",
    "                \"lr\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            torch.save(nanoGPT.state_dict(), best_model_params_path)\n",
    "\n",
    "    X,y = get_batch(\"train\")\n",
    "\n",
    "    with ctx:\n",
    "        logits, loss = nanoGPT(X, y)\n",
    "        loss = loss / gradient_accumulation_steps # scale the loss to account for gradient accumulation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "        torch.nn.utils.clip_grad_norm_(nanoGPT.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "5VvnAMRIOW_C",
    "outputId": "d1ab22d0-af11-4284-c883-7603ac132495"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
    "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
    "plt.plot(train_loss_list_converted, 'g', label = 'train_loss')\n",
    "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
    "plt.xlabel(\"Steps - Every 100 epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xlim(0, 500)\n",
    "plt.show()\n",
    "np.savetxt('train_loss.csv', train_loss_list_converted, delimiter=',')\n",
    "np.savetxt('validation_loss.csv', validation_loss_list_converted, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGuy9g2pOW_D"
   },
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "GcQS5gp2nARY",
    "outputId": "7ee68107-c84b-4f9d-be55-4f2d2255b8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 17.90M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyankadutta\\AppData\\Local\\Temp\\ipykernel_28216\\2246708991.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nanoGPT.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model\n",
    "nanoGPT = GPT.GPT(config)\n",
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "nanoGPT.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 200000\n",
      "Model vocab size: 65400\n",
      "\n",
      "Tokens: [2, 45, 9017, 1883, 78701, 4384, 45, 60957, 2525, 17636, 15, 3]\n",
      "Max token value: 78701\n",
      "Min token value: 2\n",
      "\n",
      "Warning: Some tokens are out of range!\n",
      "\n",
      "Input shape: torch.Size([1, 12])\n",
      "\n",
      "Generated text:\n",
      "[CLS] एक बर क വ്യാപാരി ह एक कदद थ।[SEP]!<pad> उस<pad>क<pad> म<pad> न<pad> এলো<unk> क<pad> उस<pad>क<pad> म<pad> न<pad> उस<pad>क<pad> मदद<pad> क<pad> ह<pad>।<pad> उस<pad>क<pad> म<pad> मस<pad>कर<pad>ई<pad> और<pad> बल<pad>,<pad> \"<pad>ન્ટ્સ[CLS]त<pad> भ<pad>,<pad> म<pad>,<pad> म<pad> हम<pad>श<pad> तम<pad>हर<pad> ल<pad>ए<pad> एक<pad> क<pad>क<pad> द<pad>ग<pad>!\"<pad> उस<pad>न<pad> कह<pad>,<pad> \"<pad>यह<pad> बह<pad>त<pad> गरम<pad> ह<pad>!<pad> चल<pad> इस<pad>क<pad> स<pad>थ<pad> क<pad>क<pad>य<pad> बन<pad> क<pad>छ<pad> क<pad>ग<pad>ज<pad> स<pad> बन<pad>हर<pad> क<pad> बन<pad>छ<pad>न<pad> क<pad> एक<pad> एक<pad> स<pad> सक<pad>क<pad>ज<pad> क<pad> ल<pad>त<pad> एक<pad>त<pad> <pad> सक<pad>स<pad>त<pad>त<pad> ह<pad>ज<pad> बन<pad>ट<pad> थ<pad>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "try:\n",
    "    indictrans_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True\n",
    "    )\n",
    "    indictrans_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"ai4bharat/indictrans2-en-indic-dist-200M\", trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    print(f\"Tokenizer vocab size: {indictrans_tokenizer.vocab_size}\")\n",
    "\n",
    "    # Ensure that your config is set up for your NanoGPT\n",
    "    print(f\"Model vocab size: {config.vocab_size}\")\n",
    "\n",
    "    # Input sentence\n",
    "    sentence = \"एक बार की बात है \"\n",
    "\n",
    "    # Tokenize input sentence\n",
    "    tokens = indictrans_tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    print(f\"\\nTokens: {tokens}\")\n",
    "    print(f\"Input token shape: {tokens.shape}\")\n",
    "\n",
    "    # Clip tokens if they exceed NanoGPT's vocabulary size\n",
    "    if tokens.max() >= config.vocab_size:\n",
    "        print(\"\\nWarning: Some tokens exceed the vocabulary size of the model!\")\n",
    "        tokens = tokens.clamp(max=config.vocab_size - 1)\n",
    "\n",
    "    # Prepare the context input\n",
    "    context = tokens.to(device)\n",
    "    print(f\"\\nContext shape: {context.shape}\")\n",
    "\n",
    "    # Set NanoGPT to evaluation mode\n",
    "    nanoGPT.eval()\n",
    "\n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        with ctx:\n",
    "            try:\n",
    "                y = nanoGPT.generate(\n",
    "                    context,\n",
    "                    max_new_tokens=200,\n",
    "                    temperature=0.8,  # Control randomness for coherent output\n",
    "                    top_k=50  # Restrict sampling for meaningful output\n",
    "                )\n",
    "\n",
    "                # Convert output tokens to text\n",
    "                generated_tokens = y[0].cpu().tolist()\n",
    "                generated_text = indictrans_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "                # Clean up generated text\n",
    "                generated_text = (\n",
    "                    generated_text.replace(\"<pad>\", \"\")\n",
    "                    .replace(\"<unk>\", \"\")\n",
    "                    .replace(\"<s>\", \"\")\n",
    "                    .replace(\"</s>\", \"\")\n",
    "                    .strip()\n",
    "                )\n",
    "\n",
    "                print(\"\\nGenerated text:\")\n",
    "                print(generated_text)\n",
    "\n",
    "            except IndexError as e:\n",
    "                print(f\"\\nIndex error during generation: {e}\")\n",
    "\n",
    "                # Handle long context issue by truncating\n",
    "                if context.size(1) > config.block_size:\n",
    "                    print(\"\\nContext is too long; truncating to fit model block size...\")\n",
    "                    context = context[:, -config.block_size:]\n",
    "                    y = nanoGPT.generate(\n",
    "                        context,\n",
    "                        max_new_tokens=50,  # Reduce the generation length for safety\n",
    "                        temperature=0.8,\n",
    "                        top_k=50\n",
    "                    )\n",
    "                    generated_tokens = y[0].cpu().tolist()\n",
    "                    generated_text = indictrans_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "                    print(\"\\nGenerated text with truncated context:\")\n",
    "                    print(generated_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference code to remove the \"padding\" and \"special characters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c4c17b9c2a44aba123fbc1990dbdf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0482b60ad9c489b9669d77a22619106",
      "placeholder": "​",
      "style": "IPY_MODEL_988e434de15e4a9dbfc84e098db9b6fd",
      "value": "config.json: 100%"
     }
    },
    "1608adce0c5a46c4b79792468e3f752e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19f45cdd0e0c4137a0449fe1e990fa69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e576622c15843b681d0b2ece9e59df8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1608adce0c5a46c4b79792468e3f752e",
      "placeholder": "​",
      "style": "IPY_MODEL_c96852b060544250b5f981745e16a8ed",
      "value": " 507/507 [00:00&lt;00:00, 43.7kB/s]"
     }
    },
    "3685092aa2c04c7887f9c4be409f38f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39732ae7fbb64ada9c507617cc7e2ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d1b2d51747a49ef8418aeead2870a49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73a244947f364462ba648439dd20d62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19f45cdd0e0c4137a0449fe1e990fa69",
      "placeholder": "​",
      "style": "IPY_MODEL_aaf94ea3be8a4773bbd0e302f14c0879",
      "value": " 5.65M/5.65M [00:00&lt;00:00, 24.0MB/s]"
     }
    },
    "7bf4e9376c914f9cb525901ca61ff1a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95bd9b75164347f286c0a0fcb46e2338": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "988e434de15e4a9dbfc84e098db9b6fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0482b60ad9c489b9669d77a22619106": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6676f1c07304d8699631a5f9312a736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3685092aa2c04c7887f9c4be409f38f6",
      "max": 5646064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9dbbb22cb8d4ed99cc3825b4a47fe94",
      "value": 5646064
     }
    },
    "a86180aae66840eab98803c8d700ae0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_beb4e69e8efb42f096c64af772a89d33",
       "IPY_MODEL_a6676f1c07304d8699631a5f9312a736",
       "IPY_MODEL_73a244947f364462ba648439dd20d62d"
      ],
      "layout": "IPY_MODEL_7bf4e9376c914f9cb525901ca61ff1a6"
     }
    },
    "aaf94ea3be8a4773bbd0e302f14c0879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aed6aa1b5b2b4d8b8bb044f247b5c2b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beb4e69e8efb42f096c64af772a89d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39732ae7fbb64ada9c507617cc7e2ae8",
      "placeholder": "​",
      "style": "IPY_MODEL_da8e8b8bfc894b98b11133aaea98cc71",
      "value": "spiece.model: 100%"
     }
    },
    "c96852b060544250b5f981745e16a8ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da8e8b8bfc894b98b11133aaea98cc71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1cb9fd654b24af39efb5ca966cc899d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95bd9b75164347f286c0a0fcb46e2338",
      "max": 507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d1b2d51747a49ef8418aeead2870a49",
      "value": 507
     }
    },
    "e331ffd1870f4cd783c550121d2fd8f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00c4c17b9c2a44aba123fbc1990dbdf6",
       "IPY_MODEL_e1cb9fd654b24af39efb5ca966cc899d",
       "IPY_MODEL_2e576622c15843b681d0b2ece9e59df8"
      ],
      "layout": "IPY_MODEL_aed6aa1b5b2b4d8b8bb044f247b5c2b4"
     }
    },
    "e9dbbb22cb8d4ed99cc3825b4a47fe94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
